import chromadb
from chromadb.config import Settings
from utils import embed_question
from dotenv import load_dotenv
from datetime import timedelta
import sqlite3
import os

load_dotenv()

REPORTS_DIR = os.getenv("REPORTS_DIR")
DB_PATH = os.getenv("DB_PATH")

client = chromadb.Client(Settings(chroma_db_impl="duckdb+parquet", persist_directory="vector_db"))
collection = client.get_or_create_collection(name="questions")

def store_questions(parsed_email):
    """Store questions and their embeddings in the vector database."""
    for log in parsed_email["logs"]:
        question = log["question"]
        vector = embed_question(question).tolist()
        collection.add(
            documents=[question],
            metadatas={"answer": log["answer"], "match_score": float(log["match_score"].replace("%", "")), "date": parsed_email["date"], "time": log["time"]},
            ids=[f"{parsed_email["date"]}_{hash(question)}"],
            embeddings=[vector]
            )

def save_report(report_text, date, folder=REPORTS_DIR):
    """Save the daily report as a markdown file in the reports folder."""
    # Ensure reports folder exists
    os.makedirs(folder, exist_ok=True)

    # Normalize date string (e.g., '2025-09-16' → '2025-09-16.json')
    filename = f"{date}.json"

    # Full path
    filepath = os.path.join(folder, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(report_text)

    print(f"✅ Report saved: {filepath}")

def init_db(db_path: str = DB_PATH):
    """Create database schema if it does not exist."""
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    # Table for individual interactions
    cur.execute("""
    CREATE TABLE IF NOT EXISTS interactions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        date TEXT,
        question TEXT,
        answer TEXT,
        match_score REAL,
        time TEXT
    )
    """)

    # Table for daily reports
    cur.execute("""
    CREATE TABLE IF NOT EXISTS daily_reports (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        date TEXT UNIQUE,
        n_logs INTEGER,
        average_match REAL,
        complete_misses INTEGER,
        complete_misses_rate REAL,
        report_text TEXT
    )
    """)

    # Table for weekly reports
    cur.execute("""
    CREATE TABLE IF NOT EXISTS weekly_reports (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        date TEXT UNIQUE,
        n_logs INTEGER,
        average_match REAL,
        complete_misses INTEGER,
        complete_misses_rate REAL,
        report_text TEXT
    )""")

    # Table for monthly reports
    cur.execute("""
    CREATE TABLE IF NOT EXISTS monthly_reports (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        date TEXT UNIQUE,
        n_logs INTEGER,
        average_match REAL,
        complete_misses INTEGER,
        complete_misses_rate REAL,
        report_text TEXT
    )
    """)

    conn.commit()
    conn.close()

def update_db(parsed_email, report_text, report_type="daily_reports", db_path: str = DB_PATH):
    """
    Save parsed interactions and the generated daily report into the database.
    parsed_email is the dict from parse_email()
    report_text is the markdown string generated by Ollama
    """
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    if report_type == "daily_reports":
        # Insert each interaction
        for log in parsed_email["logs"]:
            cur.execute("""
                INSERT INTO interactions (date, question, answer, match_score, time)
                VALUES (?, ?, ?, ?, ?)
            """, (
                parsed_email["date"],
                log["question"],
                log["answer"],
                float(log["match_score"].replace("%", "")),
                log["time"]
            ))

    # Insert or replace the daily report
    cur.execute(f"""
        INSERT OR REPLACE INTO {report_type} (date, n_logs, average_match, complete_misses, complete_misses_rate, report_text)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (
        parsed_email["date"],
        parsed_email["n_logs"],
        parsed_email["average_match"],
        parsed_email["complete_misses"],
        parsed_email["complete_misses_rate"],
        report_text
    ))

    conn.commit()
    conn.close()
    print(f"✅ Saved report and {parsed_email['n_logs']} interactions for {parsed_email['date']}")

def fetch_past_week_reports(today, db_path: str = DB_PATH):
    """Fetch daily reports from the last 7 days."""
    one_week_ago = today - timedelta(days=7)

    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    # Assuming `date` is stored in ISO format 'YYYY-MM-DD'
    cur.execute("""
        SELECT * FROM daily_reports
        WHERE date BETWEEN ? AND ?
        ORDER BY date ASC
    """, (one_week_ago.isoformat(), today.isoformat()))

    reports = cur.fetchall()
    conn.close()
    return reports  # TODO return also the date and the week range...???

def fetch_past_month_reports(today, db_path: str = DB_PATH):
    """Fetch weekly reports from the last calendar month."""
    first_day_this_month = today.replace(day=1)

    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    cur.execute("""
        SELECT * FROM weekly_reports
        WHERE date BETWEEN ? AND ?
        ORDER BY date ASC
    """, (first_day_this_month.isoformat(), today.isoformat()))

    reports = cur.fetchall()
    conn.close()
    return reports
