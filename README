# Automatic Daily, Weekly & Monthly Reporting System

This project automates the collection, analysis, and reporting of visitor interaction data. It fetches emails, parses visitor questions and answers, generates structured daily reports using a local LLM, stores the data in a local database, and saves formatted reports to disk. It also produces **weekly and monthly summaries** by aggregating daily and weekly reports.

---

## Features

* **Automated Data Collection:** Fetches emails from Gmail and filters relevant messages based on subject and sender patterns.
* **Email Parsing:** Extracts questions, answers, timestamps, and match scores from HTML email content.
* **LLM-Powered Reports:** Generates concise, structured daily, weekly, and monthly reports with insights, trends, and topic analysis using a local Ollama model.
* **Database Integration:** Stores all interactions and reports in SQLite (`daily_reports`, `weekly_reports`, `monthly_reports`) for easy querying and historical tracking.
* **Customizable Output:** Reports are additionally saved as Markdown files in `reports/` for easy inspection.
* **Extensible & Modular:** Easily add new data sources, templates, or output options.

---

## Project Structure

```
.
├── main.py                # Entry point: orchestrates fetching, parsing, reporting, and saving
├── src/
│   ├── fetch.py           # Fetches and parses emails
│   ├── prompt.py          # Builds prompts & generates reports with Ollama
│   ├── store.py           # DB schema, saving, and report persistence
│   └── utils.py           # Helper functions (e.g., totals calculation)
├── reports/               # Folder where Markdown reports are saved
├── insights.db            # SQLite database (auto-created on first run)
└── requirements.txt       # Python dependencies
```

---

## Installation

1. Clone the repository:

   ```bash
   git clone <repo-url>
   cd <repo-directory>
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Configure Gmail credentials for `simplegmail` (see https://developers.google.com/workspace/gmail/api/quickstart/python).
   
4. Install and run Ollama for local LLM inference.

---

## **Configuration Options:**

   * Update `SUBJECT_PATTERN` and `SENDER_PATTERN` in `fetch.py`.
   * Change LLM model in `prompt.generate_report`.
   * Modify report folder in `utils.save_report`.

---

## Design Choices

- Daily reports are based on **email receive date** (adjust to interaction date for future production version)
- Use **local SQLite** to store all info in a queryable database (free and simple as it is local, no server)
- Use **local LLM Ollama** to summarize and aggregate reports
- Only questions (and other relevant information) are in the report prompt, the answers are not included  
- Generate weekly report every Sunday, based on daily reports of last week
- Generate monthly report last day of each month, based on weekly reports in that month

---

## Potential Improvements

* Use a more powerful LLM API
* Use an online database integration such as Supabase
* Cluster similar questions using embeddings for better topic grouping.
* Add automated email sending of generated reports or expose them in a web dashboard.
* Enhance sentiment and language detection for richer analysis.

---

## Scheduling

To run the pipeline automatically every day:

- Windows: Use Task Scheduler
  - Trigger: Daily at 23:59:59
  - Action: Run python main.py with “Start in” set to the project folder
- Linux/macOS: Use cron